{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "pZw2REyJSce3"
      },
      "source": [
        "# Textiles Mexicanos"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "P9nqo6FShdWV"
      },
      "source": [
        "## 1. Obtención de datos\n",
        "Obtenemos el dataset del siguiente enlace https://www.mediafire.com/file/xgjtpj9pxbaly2q/UnlabeledData.zip/file, esto se hace utilizando web scraping con las librerías lxml y requests, termcolor sólo se utiliza para dar color en la salida. La instalación de las librerías se realiza de la siguiente forma. \n",
        "\n",
        "```sh\n",
        "pip install lxml requests termcolor\n",
        "```\n",
        "\n",
        "Para evitar ser baneados, declaramos un diccionario headers, que contrendrá algunos atributos que la página leerá para autenticar la petición.\n",
        "\n",
        "```python\n",
        "headers = {\n",
        "    \"user-agent\": \"Mozilla/5.0 (X11; Linux x86_64; rv:103.0) Gecko/20100101 Firefox/103.0\",\n",
        "}\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import requests\n",
        "from lxml import html\n",
        "from termcolor import cprint\n",
        "\n",
        "headers = {\n",
        "    \"user-agent\": \"Mozilla/5.0 (X11; Linux x86_64; rv:103.0) Gecko/20100101 Firefox/103.0\",\n",
        "}"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Se declara una función que descarga un archivo estático de cualquier url, por ejemplo https://www.ipn.mx/assets/files/main/img/template/logo_ipn_guinda.svg se podría descargar con la siguiente función.\n",
        "\n",
        "```python\n",
        "download_file(\n",
        "    url=\"https://www.ipn.mx/assets/files/main/img/template/logo_ipn_guinda.svg\",\n",
        "    file_name=\"ipn.svg\",\n",
        "    headers=default_headers\n",
        ")\n",
        "```\n",
        "\n",
        "La ejecución de esta función daría como resultado la descarga de este archivo en la ruta actual."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def download_file(url, file_name=\"descarga\", headers=headers):\n",
        "    if not file_name:\n",
        "        file_name = url.split(\"/\").pop()\n",
        "\n",
        "    file = requests.get(url, headers=headers)\n",
        "    downloaded = open(file_name, \"wb\")\n",
        "    downloaded.write(file.content)\n",
        "    downloaded.close()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Combinando todo lo anterior ya podemos descargar el dataset completo de mediafire y en general, cualquier archivo que se aloje dentro de esta página."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def mediafire(url, headers):\n",
        "    cprint(f\"Downloading from {url}\")\n",
        "    response = requests.get(url, headers)\n",
        "    html_text = response.text\n",
        "    parser = html.fromstring(html_text)\n",
        "    file_link = parser.xpath('//a[@class=\"input popsok\"]/@href')\n",
        "\n",
        "    cprint(f\"Downloading from {url}\", \"magenta\")\n",
        "    link = file_link[0]\n",
        "    file_name = file_link[0].split(\"/\").pop()\n",
        "    download_file(link, file_name, headers)\n",
        "    cprint(f\"file {file_name} Downloaded\", \"green\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Se descarga el dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_url = \"https://www.mediafire.com/file/xgjtpj9pxbaly2q/UnlabeledData.zip/file\"\n",
        "mediafire(data_url,headers)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Se descomprime y se guarda en la carpeta data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-lXIOLnsJzF",
        "outputId": "e2785fc8-f5d9-46e9-e1fe-50e76f420f3b"
      },
      "outputs": [],
      "source": [
        "!unzip UnlabeledData.zip\n",
        "!rm UnlabeledData.zip\n",
        "!mv UnlabeledData data"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Preprocesamiento\n",
        "La idea es trasladar una imagen a color en un vector de características que represente fielmente la información de la imagen. Importamos nuestras librerías básicas. Tenemos 2 opciones, generar las características o cargarlas de un archivo csv."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.1 Obtención de características\n",
        "\n",
        "**1 Creación de características**\n",
        "\n",
        "Para obtener las características todas las imágenes ingresarán en una red neuronal que para imágenes similares, dará vectores de características similares."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1C2CTZp7MgM7"
      },
      "outputs": [],
      "source": [
        "# Carga y preprocesamiento de Imágenes\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import load_img ,img_to_array\n",
        "from tensorflow.keras.applications.vgg16 import VGG16,preprocess_input\n",
        "\n",
        "# Model preenetrenado de extracción de características de la imagen \n",
        "from keras.applications.vgg16 import VGG16 \n",
        "from keras.models import Model"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Se instancia el modelo y truncamos la última capa para evitar que nos de clasificaciones de la imagen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S6bnaSsjR85J"
      },
      "outputs": [],
      "source": [
        "model = VGG16()\n",
        "model = Model(\n",
        "    inputs=model.inputs, \n",
        "    outputs=model.layers[-2].output\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Para automatizar este proceso, redimensionamos la imagen a 224 x 224 píxeles y esta se conserva a color, hacemos la predicción con el modelo y obtenemos un vector de características de 4096 componentes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "IPPC37_HR7Ao"
      },
      "outputs": [],
      "source": [
        "def get_features(image_path,model):\n",
        "  img = load_img(image_path, target_size=(224, 224))\n",
        "  img = np.array(img)\n",
        "\n",
        "  reshaped_img = img.reshape(1,224,224,3)\n",
        "  x = preprocess_input(reshaped_img)\n",
        "\n",
        "  features = model.predict(x)\n",
        "  return features"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Realizamos la predicción para todos los archivos de imágen que se encuentren el el directorio `data`, esto se guarda en la variable dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "M2geC0M0ivtg"
      },
      "outputs": [],
      "source": [
        "datadir = \"data\"\n",
        "files = os.listdir(datadir)\n",
        "\n",
        "dataset = [get_features(os.path.join(datadir,file),model) for file in files]\n",
        "dataset  = [vector[0] for vector in dataset]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Una vez se cargan los datos guardamos las características en un archivo csv, donde habrá 4096 columnas y varias filas, una simple tabla que contendrá toda la representación de las imágenes. Al menos mientras no se borre ningún archivo, pues todo depende totalmente del orden de los archivos, una mínima alteración en el orden arruinará todo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "labels = [f\"x{i}\" for i in range(0,4096)]\n",
        "df = pd.DataFrame(data=dataset,columns=labels)\n",
        "df.to_csv(\"Features.csv\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**2 Carga desde un archivo CSV**\n",
        "\n",
        "Para evitar todo el procesamiento anterior cada vez que se corra el notebook, mejor se carga desde un archivo csv."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.       , 0.       , 1.8900677, ..., 0.       , 0.381624 ,\n",
              "       0.       ])"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "datadir = \"data\"\n",
        "dataset = pd.read_csv(\"db/Features.csv\")\n",
        "dataset = dataset.iloc[:,:].values \n",
        "dataset[0]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "7S7Hfcd-Sgsx"
      },
      "source": [
        "### 2.2 Reducción de Dimensionalidad\n",
        "\n",
        "Se utilizará KPCA puesto que es un problema no lineal, sobre el número de componentes, se ha elegido 20 para no complicar la selección hacia atrás usada en la regresión lineal múltiple."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-fznW3uujuz",
        "outputId": "35192418-ef44-4b78-d21b-ccac1cddd8bb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 0.00337295, -0.06090929,  0.04436981, -0.07733339, -0.12020049,\n",
              "         0.04915178, -0.09281499, -0.12902319,  0.20866329, -0.09260902,\n",
              "        -0.14523923, -0.02626722, -0.13717878,  0.06608574,  0.04010848,\n",
              "        -0.02227136,  0.02576424, -0.04034996, -0.02892124,  0.0150692 ],\n",
              "       [ 0.00053323, -0.05006775,  0.03643293, -0.06397324, -0.09596588,\n",
              "         0.04327814, -0.07450606, -0.10547256,  0.16550379, -0.08068934,\n",
              "        -0.10362385, -0.02915939, -0.11921509,  0.05464905,  0.02923226,\n",
              "        -0.02347757,  0.01792858, -0.02179589, -0.01021651,  0.00256689],\n",
              "       [ 0.00297774, -0.05766386,  0.04147192, -0.07186964, -0.10992257,\n",
              "         0.04550583, -0.08263484, -0.11413934,  0.18068463, -0.08277731,\n",
              "        -0.11921536, -0.02255266, -0.11882027,  0.05382289,  0.02884547,\n",
              "        -0.03151722,  0.02116779, -0.02858183, -0.01654577,  0.00731569],\n",
              "       [-0.00248787, -0.03879777,  0.02839421, -0.05062358, -0.07212567,\n",
              "         0.03752514, -0.05701817, -0.08273231,  0.12356631, -0.06737632,\n",
              "        -0.06313945, -0.02568141, -0.09203175,  0.03656318,  0.01206848,\n",
              "        -0.03860291,  0.01285051, -0.00299711,  0.01155741, -0.01187884],\n",
              "       [ 0.00199292, -0.05481563,  0.03966102, -0.06912806, -0.10514111,\n",
              "         0.0449413 , -0.08024274, -0.1119031 ,  0.17675561, -0.08262011,\n",
              "        -0.11427986, -0.02794273, -0.12158573,  0.05713401,  0.03257369,\n",
              "        -0.01949222,  0.01945131, -0.02729477, -0.0174523 ,  0.00784393]])"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.decomposition import KernelPCA\n",
        "\n",
        "components = 20\n",
        "kpca = KernelPCA(n_components=components,kernel=\"rbf\")\n",
        "red_data =  kpca.fit_transform(dataset)\n",
        "\n",
        "red_data[:5]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Guardamos el conjunto de datos reducido en un nuevo dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "labels = [f\"x{i}\" for i in range(components)]\n",
        "df_red = pd.DataFrame(data=red_data,columns=labels)\n",
        "df_red.to_csv(\"Reduced.csv\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "QjpAtiZBvxoh"
      },
      "source": [
        "## 3 Procesamiento\n",
        "Se probarán distintos métodos de agrupamiento como K-Means y Clustering Jerárquico"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.1 K-Means\n",
        "\n",
        "Se realiza el método del codo para seleccionar el número adecuado de clusters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "8J6D_lX6vw-8",
        "outputId": "658c6d4d-91e2-4f3a-ed83-f0b7cba78641"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "sse = []\n",
        "list_k = list(range(2, 12))\n",
        "\n",
        "for k in list_k:\n",
        "    km = KMeans(n_clusters=k, random_state=22)\n",
        "    km.fit(red_data)\n",
        "    sse.append(km.inertia_)\n",
        "\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.plot(list_k, sse)\n",
        "plt.xlabel(r'Number of clusters *k*')\n",
        "plt.ylabel('Sum of squared distance')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Entrenamos el modelo de K-Means, sólo se puede entrenar uno a la vez"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "nclusters = 6\n",
        "model = KMeans(n_clusters=nclusters, random_state=22)\n",
        "model.fit(red_data)\n",
        "labels = model.labels_"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.2 Clustering Jerárquico\n",
        "Se realiza el árbol de endobrama"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from scipy.cluster.hierarchy import dendrogram, linkage\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "\n",
        "linkage_data = linkage(dataset, method='ward', metric='euclidean')\n",
        "\n",
        "dendrogram(linkage_data)\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Se han obtenido 5 clusters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "hierarchical_cluster = AgglomerativeClustering(n_clusters=6, affinity='euclidean', linkage='ward')\n",
        "labels = hierarchical_cluster.fit_predict(dataset) "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.3 Resultados del agrupamiento\n",
        "Se guardan los datos donde una columna es el archivo de la imagen y la otra es el grupo al que pertenece"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = {\n",
        "    \"image\" : os.listdir(\"data\"),\n",
        "    \"label\" : labels\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(df)\n",
        "df.to_csv(\"data.csv\")\n",
        "df"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "La siguiente función permite graficar un cluster completo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "def view_cluster(cluster,mean):\n",
        "    clusterFiles = df[df['label'] == cluster ]\n",
        "    files = clusterFiles[\"image\"].values[0:10]\n",
        "    labels = clusterFiles[\"label\"].values[0:10]\n",
        "    images = [cv2.imread(os.path.join(datadir,file)) for file in files]\n",
        "\n",
        "    fig = plt.figure(figsize=(50, 11))\n",
        "    fig.suptitle(f\"Cluster {cluster} : {mean}\",size=100)\n",
        "\n",
        "    rows = 1\n",
        "    columns = 10\n",
        "\n",
        "    for index,image in enumerate(images):\n",
        "      fig.add_subplot(rows, columns, index+1)\n",
        "      plt.imshow(image)\n",
        "      plt.axis('off')\n",
        "      plt.title(f\"{str(index)}\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Resultados de K-Means"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 859
        },
        "id": "jeMpeMyByJdM",
        "outputId": "e93e8edf-728a-4eed-b393-0d4e8a778daf"
      },
      "outputs": [],
      "source": [
        "means = [\"Zapoteco\",\"Purepecha\",\"Chinanteco\",\"Mixe\",\"Huichol\",\"Otomi\"]\n",
        "\n",
        "for index,mean in enumerate(means):\n",
        "  view_cluster(index,means[index])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Resultados de clustering jerárquico"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "means = [\"Zapoteco\",\"Purepecha\",\"Chinanteco\",\"Mixe\",\"Huichol\"]\n",
        "\n",
        "for index,mean in enumerate(means):\n",
        "  view_cluster(index,means[index])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "NV8CqOZy87C6"
      },
      "source": [
        "## 4 Evaluación\n",
        "Se usará el índice de dunn y Davis Bouldin, el primero se instalará desde una librería externa y el segundo ya viene incluido en sklearn.\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.1 Indice de Dunn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QyJuOt723ABO"
      },
      "outputs": [],
      "source": [
        "!git clone https://gitlab.com/jqmviegas/jqm_cvi jqm_cvi\n",
        "!cd jqm_cvi && mv jqmcvi ..\n",
        "!cd ..\n",
        "!rm -rf jqm_cvi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jk9kh5_j74k8",
        "outputId": "0501307c-88fa-4dea-ff0b-65bad1e6e5f9"
      },
      "outputs": [],
      "source": [
        "# Indice de Dunn\n",
        "from jqmcvi import base\n",
        "\n",
        "dun = base.dunn_fast(red_data,model.labels_)\n",
        "print(f\"Indice de Dunn {dun}\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.2 Indice de Davies Bouldin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sp2zw6yza02F",
        "outputId": "2f32fa92-d377-4ef4-fc77-652a2c16a802"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import davies_bouldin_score\n",
        "\n",
        "DB = davies_bouldin_score(red_data,model.labels_)\n",
        "print(f\"Indice de Davies Bouldin : {DB}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.8 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "vscode": {
      "interpreter": {
        "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
